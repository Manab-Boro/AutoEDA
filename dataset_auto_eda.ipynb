{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.stats import skew, kurtosis \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEDAHelper():\n",
    "    def __init__(self, df):\n",
    "        self.df= df\n",
    "        self.features_type= self.__change_datatypes()\n",
    "        self.vairables_declaration()\n",
    "\n",
    "    @property\n",
    "    def get_dataframe(self):\n",
    "        return self.df\n",
    "    \n",
    "    @property\n",
    "    def get_memory_usage(self):\n",
    "        \"\"\"memory consumption of the dataframe in bytes\"\"\"\n",
    "        return self.df.memory_usage(index=False, deep=False).sum()\n",
    "\n",
    "    @property\n",
    "    def get_duplicates_row_no(self):\n",
    "        return len(self.df)-len(self.df.drop_duplicates())\n",
    "    \n",
    "    @property\n",
    "    def get_duplicates_df(self):\n",
    "        temp= self.df.groupby(self.df.columns.tolist(),as_index=False).size().sort_values(by=[\"size\"], ascending= [False])\n",
    "        return temp[temp[\"size\"] >1]\n",
    "\n",
    "    @property\n",
    "    def get_features_type(self):\n",
    "        return self.features_type\n",
    "\n",
    "    def __change_datatypes(self, cat_threshold= 10, cat_threshold_percentage= 0.25):\n",
    "        \"\"\"checking and changing datatypes for better EDA\"\"\"\n",
    "        uni_cat= []\n",
    "        bi_cat= []\n",
    "\n",
    "        \"\"\"object to Uni-Categorical\"\"\"\n",
    "        col_list= self.df.select_dtypes(include=np.object_).columns.to_list()\n",
    "        for col in col_list:\n",
    "            unique_no= self.df[col].nunique()\n",
    "            unique_percentage= (unique_no/self.df[col].count())*100\n",
    "            if unique_no==1:\n",
    "                self.df[col]= self.df[col].astype('category')\n",
    "                uni_cat.append(col)\n",
    "        \n",
    "        \"\"\"object to Bi-Categorical\"\"\"\n",
    "        col_list= self.df.select_dtypes(include=np.object_).columns.to_list()\n",
    "        for col in col_list:\n",
    "            unique_no= self.df[col].nunique()\n",
    "            unique_percentage= (unique_no/self.df[col].count())*100\n",
    "            if unique_no== 2:\n",
    "                self.df[col]= self.df[col].astype('category')\n",
    "                bi_cat.append(col)\n",
    "        \n",
    "        \"\"\"object to Categorical\"\"\"\n",
    "        col_list= self.df.select_dtypes(include=np.object_).columns.to_list()\n",
    "        for col in col_list:\n",
    "            unique_no= self.df[col].nunique()\n",
    "            unique_percentage= (unique_no/self.df[col].count())*100\n",
    "            if unique_no< cat_threshold or unique_percentage< cat_threshold_percentage:\n",
    "                self.df[col]= self.df[col].astype('category')\n",
    "            \n",
    "\n",
    "        \"\"\"object to Datetime\"\"\"\n",
    "        col_list= self.df.select_dtypes(include=np.object_).columns.to_list()\n",
    "        for col in col_list:\n",
    "            col_list= self.df.select_dtypes(include=np.object_).columns.to_list()\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "                try:\n",
    "                    self.df[col]= pd.to_datetime(self.df[col])\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "                \n",
    "        temp= dict()\n",
    "        for col in self.df.columns.to_list():\n",
    "            if col in uni_cat:\n",
    "                temp[col]=  \"Category-Uni-Value\"\n",
    "            elif col in bi_cat:\n",
    "                temp[col]=  \"Category-Bi-Value\"\n",
    "            elif col in list(set(self.df.select_dtypes(include= 'category').columns.to_list())- set(uni_cat+bi_cat)):\n",
    "                temp[col]=  \"Category\"\n",
    "            elif col in self.df.select_dtypes(include= np.number).columns.to_list():\n",
    "                temp[col]=  \"Numeric\"\n",
    "            elif col in self.df.select_dtypes(include= 'datetime64').columns.to_list():\n",
    "                temp[col]=  \"Datetime\"\n",
    "            elif col in self.df.select_dtypes(include= 'bool').columns.to_list():\n",
    "                temp[col]=  \"Boolean\"\n",
    "            else:\n",
    "                temp[col]=  \"TEXT\"\n",
    "\n",
    "        return temp\n",
    "\n",
    "    def vairables_declaration(self):\n",
    "        #For df overview\n",
    "        self.div_class_df_overiew= \"df-div-overiew\"\n",
    "        self.img_class_logo= \"logo-img\"\n",
    "        self.table_df= \"df-table\"\n",
    "\n",
    "        self.div_class_df_details= \"df-div-details\"\n",
    "        self.para_class_df_overiew_descprtion= \"df-div-details-desc\"\n",
    "        self.div_id_df_details= \"df-details-id-\"    #nwill chnaged by the method\n",
    "        self.para_class_df_header= \"df-para-header\"\n",
    "        self.div_class_df_details_inner= \"df-div-details-inner\"\n",
    "        self.img_class_df= \"df-img-plot\"\n",
    "        self.para_class_df= \"df-paragraph\"\n",
    "\n",
    "        #For features:\n",
    "        self.div_class_ft_overiew= \"ft-div-overview\"\n",
    "        self.div_ft_overiew_id= \"ft-div-overview-id\"\n",
    "        self.div_class_ft_details_id= \"ft-div-details-id-\"  #nwill chnaged by the method\n",
    "        self.para_class_ft_overview_heading= \"ft-overview-heading\"\n",
    "        self.div_class_ft_overiew_img= \"ft-div-overview-img\"\n",
    "        self.img_class_boxplt= \"ft-img-boxplot\"\n",
    "        self.img_class_barplt= \"ft-img-barplot\"\n",
    "        self.div_class_ft_overiew_tab= \"ft-div-overview-tables\"\n",
    "        self.table_id_overview_0= \"ft-table-overview-0\"\n",
    "        self.table_id_overview_1= \"ft-table-overview-1\" \n",
    "        self.table_id_overview_2= \"ft-table-overview-2\" \n",
    "\n",
    "        self.div_class_ft_details= \"ft-div-details\"\n",
    "        self.div_class_ft_img_and_table_wraper= \"ft-div-details-inner\"\n",
    "        self.div_class_ft_details_img= \"ft-div-details-inner-img\"\n",
    "        self.img_class_countplt= \"ft-img-countplt\"\n",
    "        self.div_class_ft_details_corr= \"ft-div-details-inner-corr\"\n",
    "        self.para_class_ft_small_header_corr= \"ft-overview-corr-heading\"\n",
    "        self.para_class_ft_details_tables_header= \"ft-details-inner-tables-header\"\n",
    "        self.para_class_ft_details_tables_header_single= \"ft-details-inner-tables-header-single\"\n",
    "        self.div_class_ft_details_tables= \"ft-div-details-inner-tables\"\n",
    "        self.table_ft_details_corr_id= \"ft-table-details-corr\"\n",
    "        self.table_ft_details_id= \"ft-table-details\"\n",
    "        self.table_ft_details_single_id= \"ft-table-details-single\"\n",
    "        \n",
    "        self.datatypes_for_corr_plot= []\n",
    "        self.img_type= ''\n",
    "        self.pairplot_sample_size= ''\n",
    "        self.floating_point_limit= ''\n",
    "        \n",
    "\n",
    "\n",
    "    def df_overview_as_html(self, datatypes_for_corr_plot, pairplot_sample_size= 50, floating_point_limit=3, img_type= 'png'):\n",
    "        self.datatypes_for_corr_plot= datatypes_for_corr_plot\n",
    "        self.img_type= img_type\n",
    "        self.pairplot_sample_size= pairplot_sample_size\n",
    "        self.floating_point_limit= floating_point_limit\n",
    "\n",
    "        memory_use= self.get_memory_usage\n",
    "        Rows, Features= self.df.shape\n",
    "        duplicate_rows= self.get_duplicates_row_no\n",
    "        features_type= self.get_features_type\n",
    "        features_type= dict(Counter(features_type.values()))\n",
    "\n",
    "        top_table_1= pd.DataFrame({\n",
    "            \"Rows\": [Rows],\n",
    "            \"Features\": [Features],\n",
    "            \"Memory\": [f\"{round(memory_use/1024, floating_point_limit)} kb\"],\n",
    "            \"Duplicates\": [f\"{duplicate_rows} ({round((duplicate_rows/Rows)*100, floating_point_limit)}%)\"]\n",
    "        }).T.to_html(index= True, justify= \"justify-all\", table_id= self.table_df,header= False)\n",
    "\n",
    "        temp_dict= dict()\n",
    "        for k in features_type.keys():\n",
    "            temp_dict[k]= [features_type[k]]\n",
    "\n",
    "        top_table_2= pd.DataFrame(temp_dict).T.to_html(index= True, justify= \"justify-all\", table_id= self.table_df,header= False)\n",
    "        \n",
    "        corr_img_encoded= \"\"\n",
    "        pairplot_img_encoded= \"\"\n",
    "        corr_img_error= \"\"\n",
    "        pairplot_img_error= \"\"\n",
    "        try:\n",
    "            fig= plt.figure(figsize=(len(datatypes_for_corr_plot)*5.5, len(datatypes_for_corr_plot)*5))\n",
    "            sns.heatmap(self.df.select_dtypes(include= datatypes_for_corr_plot).apply(lambda x: x.factorize()[0]).corr(), cmap=\"YlGnBu\", annot=True,  linewidth= 5) \n",
    "            plt.xticks(rotation=45,fontsize=18)\n",
    "            plt.yticks(rotation=45,fontsize=18)\n",
    "            imgfile_2 = BytesIO()\n",
    "            fig.savefig(imgfile_2, format= img_type, bbox_inches='tight')\n",
    "            corr_img_encoded = base64.b64encode(imgfile_2.getvalue()).decode('utf-8')\n",
    "            plt.close(fig)\n",
    "        except Exception as e:\n",
    "            corr_img_error= e\n",
    "\n",
    "        if False:\n",
    "            try:\n",
    "                pairplot_img = BytesIO()\n",
    "                pairplot_fig= sns.pairplot(data= self.df.sample(n=pairplot_sample_size, random_state= 4, ignore_index= True), height= 7)\n",
    "                pairplot_fig.figure.savefig(pairplot_img, format= img_type, bbox_inches='tight')\n",
    "                pairplot_img_encoded= base64.b64encode(pairplot_img.getvalue()).decode('utf-8')\n",
    "                plt.close(pairplot_fig.fig)\n",
    "            except Exception as e:\n",
    "                pairplot_img_error= e\n",
    "        \n",
    "        df_overiew_html= f'''\n",
    "            <div class= {self.div_class_df_overiew} id=\"{self.div_ft_overiew_id}\">\n",
    "                <img class= \"{self.img_class_logo}\" src=\"pngwing.com(1).png\" alt=\"logo.png\">\n",
    "                {top_table_1}{top_table_2}\n",
    "                <p class= \"{self.para_class_df_overiew_descprtion}\">This is an auto-generated HTML page demo.<br>\n",
    "                The scope of this project is to analyze exploratory data and do some basic preprocessing autometically.\n",
    "                Find the GitHub Repo <a href=\"\">here.</a></p>\n",
    "            </div>\n",
    "        '''\n",
    "        # df_details_html= f'''\n",
    "        #     <div class= \"{self.div_class_df_details}\" id= \"{self.div_id_df_details}heatmap\">\n",
    "        #         <p class= \"{self.para_class_df_header}\">Dataframe Overiew</p>\n",
    "        #         <hr style= \"margin-right: 20px; margin-left: 20px;\">\n",
    "        #         <div class= \"{self.div_class_df_details_inner}\">\n",
    "        #             <img class= \"{self.img_class_df}\" src=\"data:image/{img_type};base64, {corr_img_encoded}\" alt=\"{corr_img_error}\" />\n",
    "        #             <hr style= \"margin-right: 25px; margin-left: 25px;\">\n",
    "        #             <p class= \"{self.para_class_df}\">Correlation Heatmap: *Data Types incuded: {datatypes_for_corr_plot}</p>\n",
    "        #         </div>\n",
    "        #     </div>\n",
    "        #     <div class= \"{self.div_class_df_details}\" id= \"{self.div_id_df_details}pairplot\">\n",
    "        #         <p class= \"{self.para_class_df_header}\">Dataframe Overiew</p>\n",
    "        #         <hr style= \"margin-right: 20px; margin-left: 20px;\">\n",
    "        #         <div class= \"{self.div_class_df_details_inner}\">\n",
    "        #             <img class= \"{self.img_class_df}\" src=\"data:image/{img_type};base64, {corr_img_encoded}\" alt=\"{pairplot_img_error}\" />\n",
    "        #             <hr style= \"margin-right: 25px; margin-left: 25px;\">\n",
    "        #             <p class= \"{self.para_class_df}\">*Ploting of Pair-plot was done on {pairplot_sample_size} random samples. (Increasing the size of sample will significantly increase process time.)</p>\n",
    "        #         </div>\n",
    "        #     </div>'''\n",
    "        df_details_html= f'''\n",
    "            <div class= \"{self.div_class_df_details}\" id= \"{self.div_id_df_details}heatmap\">\n",
    "                <p class= \"{self.para_class_df_header}\">Dataframe Overiew</p>\n",
    "                <hr style= \"margin-right: 20px; margin-left: 20px;\">\n",
    "                <div class= \"{self.div_class_df_details_inner}\">\n",
    "                    <img class= \"{self.img_class_df}\" src=\"data:image/{img_type};base64, {corr_img_encoded}\" alt=\"{corr_img_error}\" />\n",
    "                    <hr style= \"margin-right: 25px; margin-left: 25px;\">\n",
    "                    <p class= \"{self.para_class_df}\">Correlation Heatmap: *Data Types incuded: {datatypes_for_corr_plot}</p>\n",
    "                </div>\n",
    "            </div>\n",
    "            '''\n",
    "\n",
    "        return df_overiew_html, df_details_html\n",
    "\n",
    "    def feacture_as_html(self, colname):\n",
    "        feature_overiew_html= ''\n",
    "        feature_details_html= ''\n",
    "\n",
    "        if self.features_type[colname]== \"Numeric\":\n",
    "            feature_overiew_html, feature_details_html= self.num_feacture_as_html(colname)     \n",
    "                \n",
    "        elif self.features_type[colname]== \"Datetime\":\n",
    "            feature_overiew_html, feature_details_html= self.datetime_feacture_as_html(colname)\n",
    "            \n",
    "        elif self.features_type[colname]== \"Category\":\n",
    "            feature_overiew_html, feature_details_html= self.cat_feacture_as_html(colname)\n",
    "\n",
    "        elif self.features_type[colname] in  [\"Boolean\", \"Category-Bi-Value\"]:\n",
    "            feature_overiew_html= self.bi_cat_and_bool_feacture_as_html(colname)\n",
    "\n",
    "        elif self.features_type[colname]== \"Category-Uni-Value\":\n",
    "            feature_overiew_html= self.uni_cat_feacture_as_html(colname)\n",
    "        else:\n",
    "            feature_overiew_html, feature_details_html= self.text_feacture_as_html(colname)\n",
    "\n",
    "            \n",
    "        \n",
    "        return feature_overiew_html, feature_details_html\n",
    "\n",
    "    def num_feacture_as_html(self, colname):\n",
    "        desc_stats= self.num_feacture_desc_stats(colname)\n",
    "        table_1= pd.DataFrame({\n",
    "                \"Values\": [f'{desc_stats[\"Values\"].iloc[0]} ({desc_stats[\"Values_Percentage\"].iloc[0].round(self.floating_point_limit)} %)'],\n",
    "                \"Missing\": [f'{desc_stats[\"Missing\"].iloc[0]} ({desc_stats[\"Missing_Percentage\"].iloc[0].round(self.floating_point_limit)} %)'],\n",
    "                \"Distinct\": [f'{desc_stats[\"Distinct\"].iloc[0]} ({desc_stats[\"Distinct_Percentage\"].iloc[0].round(self.floating_point_limit)} %)'],\n",
    "                \"Zeros\": [f'{desc_stats[\"Zeros\"].iloc[0]} ({desc_stats[\"Zeros_Percentage\"].iloc[0].round(self.floating_point_limit)} %)'],\n",
    "            }).T.to_html(index= True, justify= \"justify-all\", table_id= self.table_id_overview_0,header= False)\n",
    "        table_2= desc_stats[[\"Min\", \"5%\", \"25%\", \"50%\", \"75%\", \"95%\", \"Max\"]].T.to_html(index= True, justify= \"justify-all\", table_id= self.table_id_overview_1,header= False)\n",
    "        table_3= pd.DataFrame({\n",
    "                \"Range\": [f'{desc_stats[\"Range\"].iloc[0].round(self.floating_point_limit)}'],\n",
    "                \"Upper Bound\": [f'{desc_stats[\"Upper_Bound\"].iloc[0].round(self.floating_point_limit)}'],\n",
    "                \"IQR\": [f'{desc_stats[\"IQR\"].iloc[0].round(self.floating_point_limit)}'],\n",
    "                \"Lower Bound\": [f'{desc_stats[\"Lower_Bound\"].iloc[0].round(self.floating_point_limit)}'],\n",
    "                \"Upper Bound <\": [f'{desc_stats[\"Gt_Upper\"].iloc[0].round(self.floating_point_limit)} ({desc_stats[\"Gt_Upper_Percentage\"].iloc[0].round(self.floating_point_limit)} %)'],\n",
    "                \"Lower Bound >\": [f'{desc_stats[\"Lt_Lower\"].iloc[0].round(self.floating_point_limit)} ({desc_stats[\"Lt_Lower_Percentage\"].iloc[0].round(self.floating_point_limit)} %)'],\n",
    "            }).T.to_html(index= True, justify= \"justify-all\", table_id= self.table_id_overview_1,header= False)\n",
    "        table_4= desc_stats[[\"Std\", \"Var\", \"Skew\", \"Kurtosis\"]].round(self.floating_point_limit).T.to_html(index= True, justify= \"justify-all\", table_id= self.table_id_overview_1,header= False)\n",
    "\n",
    "\n",
    "        pear_corr= self.df.select_dtypes(include= np.number).corr('pearson')[colname]\n",
    "        ken_corr= self.df.select_dtypes(include= np.number).corr(method='kendall')[colname]\n",
    "\n",
    "        right_table_1= pd.DataFrame({\n",
    "            \"Colname\": pear_corr.index,\n",
    "            \"Value\": pear_corr\n",
    "        }).to_html(index= False, justify= \"justify-all\", table_id= self.table_ft_details_corr_id,header= False)\n",
    "        right_table_2= pd.DataFrame({\n",
    "            \"Colname\": ken_corr.index,\n",
    "            \"Value\": ken_corr\n",
    "        }).to_html(index= False, justify= \"justify-all\", table_id= self.table_ft_details_corr_id,header= False)\n",
    "\n",
    "        top_freq= self.df[[colname]].sort_index(ascending= False).value_counts().sort_values(ascending= False).nlargest(15).reset_index()\n",
    "        top_freq[\"Count_Percentage\"]= (top_freq[\"count\"]/self.df[colname].count())*100\n",
    "        top_freq[colname]= top_freq[colname].astype(str)\n",
    "        top_freq.loc[len(top_freq)]= [\"others...\", len(self.df[colname].notnull())-top_freq[\"count\"].sum(), 100-top_freq[\"Count_Percentage\"].sum()]\n",
    "\n",
    "\n",
    "        smallest_val= self.df[[colname]].value_counts().reset_index().sort_values(by= [colname]).nsmallest(15, columns= [colname])\n",
    "        smallest_val[\"Count_Percentage\"]= (smallest_val[\"count\"]/self.df[colname].count())*100\n",
    "        smallest_val[colname]= smallest_val[colname].astype(str)\n",
    "        smallest_val.loc[len(smallest_val)]= [\"others...\", len(self.df[colname].notnull())-smallest_val[\"count\"].sum(), 100-smallest_val[\"Count_Percentage\"].sum()]\n",
    "\n",
    "        lagest_val= self.df[[colname]].value_counts().reset_index().sort_values(by= [colname]).nlargest(15, columns= [colname])\n",
    "        lagest_val[\"Count_Percentage\"]= (lagest_val[\"count\"]/self.df[colname].count())*100\n",
    "        lagest_val[colname]= lagest_val[colname].astype(str)\n",
    "        lagest_val.loc[len(lagest_val)]= [\"others...\", len(self.df[colname].notnull())-lagest_val[\"count\"].sum(), 100-lagest_val[\"Count_Percentage\"].sum()]\n",
    "\n",
    "        right_table_3= pd.DataFrame({\n",
    "            \"Data\": top_freq[colname],\n",
    "            \"Count\": top_freq[\"count\"].astype(str) + \" (\"+ top_freq[\"Count_Percentage\"].round(self.floating_point_limit).astype(str)+ \"%)\",\n",
    "        }).to_html(index= False, justify= \"justify-all\", table_id= self.table_ft_details_id,header= False)\n",
    "        right_table_4= pd.DataFrame({\n",
    "            \"Data\": smallest_val[colname],\n",
    "            \"Count\": smallest_val[\"count\"].astype(str) + \" (\"+ smallest_val[\"Count_Percentage\"].round(self.floating_point_limit).astype(str)+ \"%)\",\n",
    "        }).to_html(index= False, justify= \"justify-all\", table_id= self.table_ft_details_id,header= False)\n",
    "        right_table_5= pd.DataFrame({\n",
    "            \"Data\": lagest_val[colname],\n",
    "            \"Count\": lagest_val[\"count\"].astype(str) + \" (\"+ lagest_val[\"Count_Percentage\"].round(self.floating_point_limit).astype(str)+ \"%)\",\n",
    "        }).to_html(index= False, justify= \"justify-all\", table_id= self.table_ft_details_id,header= False)\n",
    "        \n",
    "        \"\"\"box plot\"\"\"\n",
    "        box_fig= plt.figure(figsize=(12,5))\n",
    "        sns.boxplot(data=self.df, x= colname,color=\"red\")\n",
    "        box_fig_tmpfile = BytesIO()\n",
    "        box_fig.savefig(box_fig_tmpfile, format=self.img_type, bbox_inches='tight')\n",
    "        box_encoded = base64.b64encode(box_fig_tmpfile.getvalue()).decode('utf-8')\n",
    "        plt.close(box_fig)\n",
    "        \"\"\"count plot\"\"\"\n",
    "        count_fig= plt.figure(figsize=(17,14))\n",
    "        sns.countplot(data=self.df, x= colname,color=\"red\")\n",
    "        count_fig_tmpfile = BytesIO()\n",
    "        count_fig.savefig(count_fig_tmpfile, format=self.img_type, bbox_inches='tight')\n",
    "        count_encoded = base64.b64encode(count_fig_tmpfile.getvalue()).decode('utf-8')\n",
    "        plt.close(count_fig)\n",
    "        \n",
    "        feature_overiew_html= f'''\n",
    "            <div class= \"{self.div_class_ft_overiew}\" onclick= \"displayrightdiv('{self.div_class_ft_details_id}{colname}', '{self.div_class_ft_details}');\">\n",
    "                <p class =\"{self.para_class_ft_overview_heading}\">{self.df.columns.get_loc(colname)+1} {colname} ({self.features_type[colname]})</p>\n",
    "                <div class= \"{self.div_class_ft_overiew_img}\">\n",
    "                    <img class= \"{self.img_class_boxplt}\" src=\"data:image/{self.img_type};base64,{box_encoded}\" alt=\"Graph\">\n",
    "                </div>\n",
    "                <div class= \"{self.div_class_ft_overiew_tab}\">\n",
    "                    {table_1}{table_2}{table_3}{table_4}\n",
    "                </div>\n",
    "            </div>'''\n",
    "        \n",
    "        feature_details_html= f'''\n",
    "            <div class= \"{self.div_class_ft_details}\" id= \"{self.div_class_ft_details_id}{colname}\">\n",
    "                <p class =\"{self.para_class_df_header}\">{colname}</p>\n",
    "                <hr style=\"margin-left: 25px; margin-right: 25px;\">\n",
    "                <div class=\"{self.div_class_ft_img_and_table_wraper}\">\n",
    "                    <div class= \"{self.div_class_ft_details_img}\">\n",
    "                        <img class= \"{self.img_class_countplt}\" src=\"data:image/{self.img_type};base64,{count_encoded}\" alt=\"Graph\">\n",
    "                    </div>\n",
    "                    <div class= \"{self.div_class_ft_details_corr}\">\n",
    "                        <p class=\"{self.para_class_ft_small_header_corr}\">Correlation: Pearson</p>{right_table_1}<p class=\"{self.para_class_ft_small_header_corr}\">Correlation: Kendall</p>{right_table_2}\n",
    "                    </div>\n",
    "                </div>\n",
    "                <div class= \"{self.div_class_ft_details_tables}\">\n",
    "                    <hr style=\"margin-left: 25px; margin-right: 25px;\">\n",
    "                    <p class= \"{self.para_class_ft_details_tables_header}\">Top Frequent</p>\n",
    "                    <p class= \"{self.para_class_ft_details_tables_header}\">Top Smallest Values</p>\n",
    "                    <p class= \"{self.para_class_ft_details_tables_header}\">Top Largest Values</p>\n",
    "                    {right_table_3}{right_table_4}{right_table_5}\n",
    "                </div>\n",
    "            </div>'''\n",
    "\n",
    "        return feature_overiew_html, feature_details_html\n",
    "\n",
    "    def datetime_feacture_as_html(self, colname):\n",
    "        no_of_rows_right= 50\n",
    "        no_of_rows_left= 7\n",
    "\n",
    "        desc_stats= self.datetime_feacture_desc_stats(colname)\n",
    "        temp= pd.DataFrame(self.df[colname].value_counts().nlargest(no_of_rows_left)).reset_index()\n",
    "        temp[colname]= temp[colname].astype(str)\n",
    "        temp.loc[len(temp)]= [\"others...\", self.df[colname].count()- temp[\"count\"].sum()]\n",
    "        temp[\"Count_Percentage\"]= (temp[\"count\"]/self.df[colname].count())*100\n",
    "        temp= temp.round(decimals=self.floating_point_limit)\n",
    "\n",
    "        bar_fig= plt.figure(figsize=(15,5))\n",
    "        sns.barplot(data=temp, x=colname, y=\"count\", color= \"blue\")\n",
    "        bar_fig_tmpfile = BytesIO()\n",
    "        bar_fig.savefig(bar_fig_tmpfile, format=self.img_type, bbox_inches='tight')\n",
    "        bar_encoded = base64.b64encode(bar_fig_tmpfile.getvalue()).decode('utf-8')\n",
    "        plt.close(bar_fig)\n",
    "\n",
    "        table_1= pd.DataFrame({\n",
    "            \"Values\": [f'{desc_stats[\"Values\"].iloc[0]} ({desc_stats[\"Values_Percentage\"].iloc[0].round(self.floating_point_limit)} %)'],\n",
    "            \"Missing\": [f'{desc_stats[\"Missing\"].iloc[0]} ({desc_stats[\"Missing_Percentage\"].iloc[0].round(self.floating_point_limit)} %)'],\n",
    "            \"Distinct\": [f'{desc_stats[\"Distinct\"].iloc[0]} ({desc_stats[\"Distinct_Percentage\"].iloc[0].round(self.floating_point_limit)} %)']\n",
    "        }).T.to_html(index= True, justify= \"justify-all\", table_id= self.table_id_overview_0, header= False)\n",
    "        table_2= desc_stats[[\"Start\", \"End\", \"Std\"]].T.to_html(index= True, justify= \"justify-all\", table_id= self.table_id_overview_1, header= False)\n",
    "        table_3= pd.DataFrame({\n",
    "            \"Date\": temp[colname],\n",
    "            \"Values\": temp[\"count\"].astype(str)+ \" (\"+ temp[\"Count_Percentage\"].astype(str)+ \"%)\",\n",
    "        }).to_html(index= False, justify= \"justify-all\", table_id= self.table_id_overview_2, header= False)\n",
    "\n",
    "        #for right tab\n",
    "        top_freq= self.df[[colname]].sort_index(ascending= False).value_counts().sort_values(ascending= False).nlargest(no_of_rows_right).reset_index()\n",
    "        top_freq[\"Count_Percentage\"]= (top_freq[\"count\"]/self.df[colname].count())*100\n",
    "        top_freq.loc[len(top_freq)]= [\"others...\", len(self.df[colname].notnull())-top_freq[\"count\"].sum(), 100-top_freq[\"Count_Percentage\"].sum()]\n",
    "\n",
    "        smallest_val= self.df[[colname]].value_counts().reset_index().sort_values(by= [colname]).nsmallest(no_of_rows_right, columns= [colname])\n",
    "        smallest_val[\"Count_Percentage\"]= (smallest_val[\"count\"]/self.df[colname].count())*100\n",
    "        smallest_val.loc[len(smallest_val)]= [\"others...\", len(self.df[colname].notnull())-smallest_val[\"count\"].sum(), 100-smallest_val[\"Count_Percentage\"].sum()]\n",
    "\n",
    "        lagest_val= self.df[[colname]].value_counts().reset_index().sort_values(by= [colname]).nlargest(no_of_rows_right, columns= [colname])\n",
    "        lagest_val[\"Count_Percentage\"]= (lagest_val[\"count\"]/self.df[colname].count())*100\n",
    "        lagest_val.loc[len(lagest_val)]= [\"others...\", len(self.df[colname].notnull())-lagest_val[\"count\"].sum(), 100-lagest_val[\"Count_Percentage\"].sum()]\n",
    "\n",
    "        right_table_3= pd.DataFrame({\n",
    "            \"Data\": top_freq[colname],\n",
    "            \"Count\": top_freq[\"count\"].astype(str) + \" (\"+ top_freq[\"Count_Percentage\"].round(self.floating_point_limit).astype(str)+ \"%)\",\n",
    "        }).to_html(index= False, justify= \"justify-all\", table_id= self.table_ft_details_id, header= False)\n",
    "        right_table_4= pd.DataFrame({\n",
    "            \"Data\": smallest_val[colname],\n",
    "            \"Count\": smallest_val[\"count\"].astype(str) + \" (\"+ smallest_val[\"Count_Percentage\"].round(self.floating_point_limit).astype(str)+ \"%)\",\n",
    "        }).to_html(index= False, justify= \"justify-all\", table_id= self.table_ft_details_id, header= False)\n",
    "        right_table_5= pd.DataFrame({\n",
    "            \"Data\": lagest_val[colname],\n",
    "            \"Count\": lagest_val[\"count\"].astype(str) + \" (\"+ lagest_val[\"Count_Percentage\"].round(self.floating_point_limit).astype(str)+ \"%)\",\n",
    "        }).to_html(index= False, justify= \"justify-all\", table_id= self.table_ft_details_id, header= False)\n",
    "        \n",
    "        feature_overiew_html= f'''\n",
    "            <div class= \"{self.div_class_ft_overiew}\" onclick= \"displayrightdiv('{self.div_class_ft_details_id}{colname}', '{self.div_class_ft_details}');\">\n",
    "                <p class =\"{self.para_class_ft_overview_heading}\">{self.df.columns.get_loc(colname)+1} {colname} ({self.features_type[colname]})</p>\n",
    "                <div class= \"{self.div_class_ft_overiew_img}\">\n",
    "                    <img class= \"{self.img_class_barplt}\" src=\"data:image/{self.img_type};base64,{bar_encoded}\" alt=\"Graph\">\n",
    "                </div>\n",
    "                <div class= \"{self.div_class_ft_overiew_tab}\">\n",
    "                    {table_1}{table_2}{table_3}\n",
    "                </div>\n",
    "            </div>'''\n",
    "        feature_details_html= f'''\n",
    "            <div class= \"{self.div_class_ft_details}\" id= \"{self.div_class_ft_details_id}{colname}\">\n",
    "                <p class =\"{self.para_class_df_header}\">{colname}</p>\n",
    "                <hr style=\"margin-left: 25px; margin-right: 25px;\">\n",
    "                <div class= \"{self.div_class_ft_details_tables}\">\n",
    "                    <p class= \"{self.para_class_ft_details_tables_header}\">Top Frequent</p>\n",
    "                    <p class= \"{self.para_class_ft_details_tables_header}\">Earliest Dates/Times</p>\n",
    "                    <p class= \"{self.para_class_ft_details_tables_header}\">Latest Dates/Times</p>\n",
    "                    {right_table_3}{right_table_4}{right_table_5}\n",
    "                </div>\n",
    "            </div>'''\n",
    "        return feature_overiew_html, feature_details_html\n",
    "\n",
    "    def cat_feacture_as_html(self, colname):\n",
    "        no_of_rows_right= 50\n",
    "        no_of_rows_left= 7\n",
    "\n",
    "        desc_stats= self.cat_feacture_desc_stats(colname)\n",
    "        temp= pd.DataFrame(self.df[colname].value_counts().nlargest(no_of_rows_left)).reset_index()\n",
    "        temp[colname]= temp[colname].astype(str)\n",
    "        temp.loc[len(temp)]= [\"others...\", self.df[colname].count()- temp[\"count\"].sum()]\n",
    "        temp[\"Count_Percentage\"]= (temp[\"count\"]/self.df[colname].count())*100\n",
    "        temp= temp.round(decimals=self.floating_point_limit)\n",
    "\n",
    "        bar_fig= plt.figure(figsize=(15,5))\n",
    "        sns.barplot(data=temp, x=colname, y=\"count\", color= \"purple\")\n",
    "        bar_fig_tmpfile = BytesIO()\n",
    "        bar_fig.savefig(bar_fig_tmpfile, format=self.img_type, bbox_inches='tight')\n",
    "        bar_encoded = base64.b64encode(bar_fig_tmpfile.getvalue()).decode('utf-8')\n",
    "        plt.close(bar_fig)\n",
    "\n",
    "        table_1= pd.DataFrame({\n",
    "            \"Values\": [f'{desc_stats[\"Values\"].iloc[0]} ({desc_stats[\"Values_Percentage\"].iloc[0].round(self.floating_point_limit)} %)'],\n",
    "            \"Missing\": [f'{desc_stats[\"Missing\"].iloc[0]} ({desc_stats[\"Missing_Percentage\"].iloc[0].round(self.floating_point_limit)} %)'],\n",
    "            \"Distinct\": [f'{desc_stats[\"Distinct\"].iloc[0]} ({desc_stats[\"Distinct_Percentage\"].iloc[0].round(self.floating_point_limit)} %)']\n",
    "        }).T.to_html(index= True, justify= \"justify-all\", table_id= self.table_id_overview_0, header= False)\n",
    "        table_3= pd.DataFrame({\n",
    "            \"Date\": temp[colname],\n",
    "            \"Values\": temp[\"count\"].astype(str)+ \" (\"+ temp[\"Count_Percentage\"].astype(str)+ \"%)\",\n",
    "        }).to_html(index= False, justify= \"justify-all\", table_id= self.table_id_overview_2, header= False)\n",
    "\n",
    "        #for right tab\n",
    "        top_freq= self.df[[colname]].sort_index(ascending= False).value_counts().sort_values(ascending= False).nlargest(no_of_rows_right).reset_index()\n",
    "        top_freq[\"Count_Percentage\"]= (top_freq[\"count\"]/self.df[colname].count())*100\n",
    "        top_freq.loc[len(top_freq)]= [\"others...\", len(self.df[colname].notnull())-top_freq[\"count\"].sum(), 100-top_freq[\"Count_Percentage\"].sum()]\n",
    "\n",
    "        right_table_3= pd.DataFrame({\n",
    "            \"Data\": top_freq[colname],\n",
    "            \"Count\": top_freq[\"count\"].astype(str) + \" (\"+ top_freq[\"Count_Percentage\"].round(self.floating_point_limit).astype(str)+ \"%)\",\n",
    "        }).to_html(index= False, justify= \"justify-all\", table_id= self.table_ft_details_single_id, header= False)\n",
    "        \n",
    "        feature_overiew_html= f'''\n",
    "            <div class= \"{self.div_class_ft_overiew}\" onclick= \"displayrightdiv('{self.div_class_ft_details_id}{colname}', '{self.div_class_ft_details}');\">\n",
    "                <p class =\"{self.para_class_ft_overview_heading}\">{self.df.columns.get_loc(colname)+1} {colname} ({self.features_type[colname]})</p>\n",
    "                <div class= \"{self.div_class_ft_overiew_img}\">\n",
    "                    <img class= \"{self.img_class_barplt}\" src=\"data:image/{self.img_type};base64,{bar_encoded}\" alt=\"Graph\">\n",
    "                </div>\n",
    "                <div class= \"{self.div_class_ft_overiew_tab}\">\n",
    "                    {table_1}{table_3}\n",
    "                </div>\n",
    "            </div>'''\n",
    "        feature_details_html= f'''\n",
    "            <div class= \"{self.div_class_ft_details}\" id= \"{self.div_class_ft_details_id}{colname}\">\n",
    "                <p class =\"{self.para_class_df_header}\">{colname}</p>\n",
    "                <hr style=\"margin-left: 25px; margin-right: 25px;\">\n",
    "                <div class= \"{self.div_class_ft_details_tables}\">\n",
    "                    <p class= \"{self.para_class_ft_details_tables_header_single}\">Top Frequent</p>\n",
    "                    {right_table_3}\n",
    "                </div>\n",
    "            </div>'''\n",
    "        return feature_overiew_html, feature_details_html\n",
    "\n",
    "    def text_feacture_as_html(self, colname):\n",
    "        no_of_rows_right= 50\n",
    "        no_of_rows_left= 7\n",
    "\n",
    "        desc_stats= self.cat_feacture_desc_stats(colname)\n",
    "        temp= pd.DataFrame(self.df[colname].value_counts().nlargest(no_of_rows_left)).reset_index()\n",
    "        temp[colname]= temp[colname].astype(str)\n",
    "        temp.loc[len(temp)]= [\"others...\", self.df[colname].count()- temp[\"count\"].sum()]\n",
    "        temp[\"Count_Percentage\"]= (temp[\"count\"]/self.df[colname].count())*100\n",
    "        temp= temp.round(decimals=self.floating_point_limit)\n",
    "\n",
    "        table_1= pd.DataFrame({\n",
    "            \"Values\": [f'{desc_stats[\"Values\"].iloc[0]} ({desc_stats[\"Values_Percentage\"].iloc[0].round(self.floating_point_limit)} %)'],\n",
    "            \"Missing\": [f'{desc_stats[\"Missing\"].iloc[0]} ({desc_stats[\"Missing_Percentage\"].iloc[0].round(self.floating_point_limit)} %)'],\n",
    "            \"Distinct\": [f'{desc_stats[\"Distinct\"].iloc[0]} ({desc_stats[\"Distinct_Percentage\"].iloc[0].round(self.floating_point_limit)} %)']\n",
    "        }).T.to_html(index= True, justify= \"justify-all\", table_id= self.table_id_overview_0, header= False)\n",
    "        table_3= pd.DataFrame({\n",
    "            \"Date\": temp[colname],\n",
    "            \"Values\": temp[\"count\"].astype(str)+ \" (\"+ temp[\"Count_Percentage\"].astype(str)+ \"%)\",\n",
    "        }).to_html(index= False, justify= \"justify-all\", table_id= self.table_id_overview_2, header= False)\n",
    "\n",
    "        #for right tab\n",
    "        top_freq= self.df[[colname]].sort_index(ascending= False).value_counts().sort_values(ascending= False).nlargest(no_of_rows_right).reset_index()\n",
    "        top_freq[\"Count_Percentage\"]= (top_freq[\"count\"]/self.df[colname].count())*100\n",
    "        top_freq.loc[len(top_freq)]= [\"others...\", len(self.df[colname].notnull())-top_freq[\"count\"].sum(), 100-top_freq[\"Count_Percentage\"].sum()]\n",
    "\n",
    "        right_table_3= pd.DataFrame({\n",
    "            \"Data\": top_freq[colname],\n",
    "            \"Count\": top_freq[\"count\"].astype(str) + \" (\"+ top_freq[\"Count_Percentage\"].round(self.floating_point_limit).astype(str)+ \"%)\",\n",
    "        }).to_html(index= False, justify= \"justify-all\", table_id= self.table_ft_details_single_id, header= False)\n",
    "        \n",
    "        feature_overiew_html= f'''\n",
    "            <div class= \"{self.div_class_ft_overiew}\" onclick= \"displayrightdiv('{self.div_class_ft_details_id}{colname}', '{self.div_class_ft_details}');\">\n",
    "                <p class =\"{self.para_class_ft_overview_heading}\">{self.df.columns.get_loc(colname)+1} {colname} ({self.features_type[colname]})</p>\n",
    "                <div class= \"{self.div_class_ft_overiew_tab}\">\n",
    "                    {table_1}{table_3}\n",
    "                </div>\n",
    "            </div>'''\n",
    "        feature_details_html= f'''\n",
    "            <div class= \"{self.div_class_ft_details}\" id= \"{self.div_class_ft_details_id}{colname}\">\n",
    "                <p class =\"{self.para_class_df_header}\">{colname}</p>\n",
    "                <hr style=\"margin-left: 25px; margin-right: 25px;\">\n",
    "                <div class= \"{self.div_class_ft_details_tables}\">\n",
    "                    <p class= \"{self.para_class_ft_details_tables_header_single}\">Top Frequent</p>\n",
    "                    {right_table_3}\n",
    "                </div>\n",
    "            </div>'''\n",
    "        return feature_overiew_html, feature_details_html\n",
    "\n",
    "    def bi_cat_and_bool_feacture_as_html(self, colname):\n",
    "        desc_stats= self.cat_feacture_desc_stats(colname)\n",
    "        temp= pd.DataFrame(self.df[colname].value_counts().nlargest(2)).reset_index()\n",
    "        temp[\"Count_Percentage\"]= (temp[\"count\"]/self.df[colname].count())*100\n",
    "        temp= temp.round(decimals=self.floating_point_limit)\n",
    "\n",
    "        desc_stats= self.cat_feacture_desc_stats(colname)\n",
    "        temp= pd.DataFrame(self.df[colname].value_counts().nlargest(2)).reset_index()\n",
    "        temp[colname]= temp[colname].astype(str)\n",
    "        temp.loc[len(temp)]= [\"others...\", self.df[colname].count()- temp[\"count\"].sum()]\n",
    "        temp[\"Count_Percentage\"]= (temp[\"count\"]/self.df[colname].count())*100\n",
    "        temp= temp.round(decimals=self.floating_point_limit)\n",
    "\n",
    "        bar_fig= plt.figure(figsize=(15,5))\n",
    "        sns.barplot(data=temp, x=colname, y=\"count\", color= \"cyan\")\n",
    "        bar_fig_tmpfile = BytesIO()\n",
    "        bar_fig.savefig(bar_fig_tmpfile, format=self.img_type, bbox_inches='tight')\n",
    "        bar_encoded = base64.b64encode(bar_fig_tmpfile.getvalue()).decode('utf-8')\n",
    "        plt.close(bar_fig)\n",
    "\n",
    "        table_1= pd.DataFrame({\n",
    "            \"Values\": [f'{desc_stats[\"Values\"].iloc[0]} ({desc_stats[\"Values_Percentage\"].iloc[0].round(self.floating_point_limit)} %)'],\n",
    "            \"Missing\": [f'{desc_stats[\"Missing\"].iloc[0]} ({desc_stats[\"Missing_Percentage\"].iloc[0].round(self.floating_point_limit)} %)'],\n",
    "            \"Distinct\": [f'{desc_stats[\"Distinct\"].iloc[0]} ({desc_stats[\"Distinct_Percentage\"].iloc[0].round(self.floating_point_limit)} %)']\n",
    "        }).T.to_html(index= True, justify= \"justify-all\", table_id= self.table_id_overview_0, header= False)\n",
    "        table_3= pd.DataFrame({\n",
    "            \"Date\": temp[colname],\n",
    "            \"Values\": temp[\"count\"].astype(str)+ \" (\"+ temp[\"Count_Percentage\"].astype(str)+ \"%)\",\n",
    "        }).to_html(index= False, justify= \"justify-all\", table_id= self.table_id_overview_2, header= False)\n",
    "        \n",
    "        feature_overiew_html= f'''\n",
    "            <div class= \"{self.div_class_ft_overiew}\" id=\"{self.div_ft_overiew_id}\">\n",
    "                <p class =\"{self.para_class_ft_overview_heading}\">{self.df.columns.get_loc(colname)+1} {colname} ({self.features_type[colname]})</p>\n",
    "                <div class= \"{self.div_class_ft_overiew_img}\">\n",
    "                    <img class= \"{self.img_class_barplt}\" src=\"data:image/{self.img_type};base64,{bar_encoded}\" alt=\"Graph\">\n",
    "                </div>\n",
    "                <div class= \"{self.div_class_ft_overiew_tab}\">\n",
    "                    {table_1}{table_3}\n",
    "                </div>\n",
    "            </div>'''\n",
    "        return feature_overiew_html\n",
    "\n",
    "    def uni_cat_feacture_as_html(self, colname):\n",
    "        desc_stats= self.cat_feacture_desc_stats(colname)\n",
    "        temp= pd.DataFrame(self.df[colname].value_counts().nlargest(2)).reset_index()\n",
    "        temp[\"Count_Percentage\"]= (temp[\"count\"]/self.df[colname].count())*100\n",
    "        temp= temp.round(decimals=self.floating_point_limit)\n",
    "\n",
    "        table_1= pd.DataFrame({\n",
    "            \"Values\": [f'{desc_stats[\"Values\"].iloc[0]} ({desc_stats[\"Values_Percentage\"].iloc[0].round(self.floating_point_limit)} %)'],\n",
    "            \"Missing\": [f'{desc_stats[\"Missing\"].iloc[0]} ({desc_stats[\"Missing_Percentage\"].iloc[0].round(self.floating_point_limit)} %)'],\n",
    "            \"Distinct\": [f'{desc_stats[\"Distinct\"].iloc[0]} ({desc_stats[\"Distinct_Percentage\"].iloc[0].round(self.floating_point_limit)} %)']\n",
    "        }).T.to_html(index= True, justify= \"justify-all\", table_id= self.table_id_overview_0, header= False)\n",
    "        table_3= pd.DataFrame({\n",
    "            \"Date\": temp[colname],\n",
    "            \"Values\": temp[\"count\"].astype(str)+ \" (\"+ temp[\"Count_Percentage\"].astype(str)+ \"%)\",\n",
    "        }).to_html(index= False, justify= \"justify-all\", table_id= self.table_id_overview_2, header= False)\n",
    "        \n",
    "        feature_overiew_html= f'''\n",
    "            <div class= \"{self.div_class_ft_overiew}\" id=\"{self.div_ft_overiew_id}\">\n",
    "                <p class =\"{self.para_class_ft_overview_heading}\">{self.df.columns.get_loc(colname)+1} {colname} ({self.features_type[colname]})</p>\n",
    "                <div class= \"{self.div_class_ft_overiew_tab}\">\n",
    "                    {table_1}{table_3}\n",
    "                </div>\n",
    "            </div>'''\n",
    "        return feature_overiew_html\n",
    "\n",
    "    def num_feacture_desc_stats(self, colname):\n",
    "        temp= self.df[colname]\n",
    "        desc_stats= temp.describe(percentiles=[0.05, 0.25, 0.5, 0.75, 0.95]).to_frame().T\n",
    "\n",
    "        desc_stats[\"sum\"]= np.sum(temp, axis=0)\n",
    "        desc_stats[\"skew\"]= skew(temp, axis=0, bias=False, nan_policy='omit')\n",
    "        desc_stats[\"kurtosis\"]= kurtosis(temp, axis=0, bias=False, nan_policy='omit')\n",
    "        desc_stats[\"var\"]= np.var(temp, axis=0)\n",
    "        desc_stats[\"Range\"]= desc_stats[\"max\"]- desc_stats[\"min\"]\n",
    "        desc_stats[\"IQR\"]= desc_stats[\"75%\"]- desc_stats[\"25%\"]\n",
    "        desc_stats[\"Upper_Bound\"]= desc_stats[\"75%\"]+ (1.5* desc_stats[\"IQR\"])\n",
    "        desc_stats[\"Lower_Bound\"]= desc_stats[\"25%\"]- (1.5* desc_stats[\"IQR\"])\n",
    "        desc_stats[\"Missing\"]= temp.isnull().sum()\n",
    "        desc_stats[\"Missing_Percentage\"]= (desc_stats[\"Missing\"]/(desc_stats[\"count\"]+ desc_stats[\"Missing\"]))* 100\n",
    "        desc_stats[\"Distinct\"]= temp.nunique()\n",
    "        desc_stats[\"Distinct_Percentage\"]= (desc_stats[\"Distinct\"]/(desc_stats[\"count\"]+ desc_stats[\"Missing\"]))* 100\n",
    "        desc_stats[\"count\"]= desc_stats[\"count\"].astype(np.int64)\n",
    "        desc_stats[\"Zeros\"]= temp[temp==0].count()\n",
    "        desc_stats[\"Zeros_Percentage\"]= (desc_stats[\"Zeros\"]/(desc_stats[\"count\"]+ desc_stats[\"Missing\"]))* 100\n",
    "        desc_stats[\"Values_Percentage\"]= 100- desc_stats[\"Missing_Percentage\"]\n",
    "\n",
    "        gt_upper= 0\n",
    "        lt_lower= 0\n",
    "\n",
    "        gt_upper= temp.gt(desc_stats[\"Upper_Bound\"].iloc[0]).sum()\n",
    "        lt_lower= temp.lt(desc_stats[\"Lower_Bound\"].iloc[0]).sum()\n",
    "\n",
    "        desc_stats[\"Gt_Upper\"]= gt_upper\n",
    "        desc_stats[\"Gt_Upper_Percentage\"]= (desc_stats[\"Gt_Upper\"]/desc_stats[\"count\"])* 100\n",
    "        desc_stats[\"Lt_Lower\"]= lt_lower\n",
    "        desc_stats[\"Lt_Lower_Percentage\"]= (desc_stats[\"Lt_Lower\"]/desc_stats[\"count\"])* 100\n",
    "\n",
    "        desc_stats.rename(columns=\n",
    "                        {\n",
    "                            \"count\": \"Values\", \n",
    "                            \"mean\": \"Avg\",\n",
    "                            \"std\": \"Std\",\n",
    "                            \"min\": \"Min\",\n",
    "                            \"max\": \"Max\",\n",
    "                            \"sum\": \"Sum\",\n",
    "                            \"skew\": \"Skew\",\n",
    "                            \"kurtosis\": \"Kurtosis\",\n",
    "                            \"var\": \"Var\"\n",
    "                        }, inplace= True\n",
    "                    )\n",
    "\n",
    "        return desc_stats\n",
    "\n",
    "    def datetime_feacture_desc_stats(self, colname):\n",
    "        temp=  self.df[colname]\n",
    "        desc_stats= pd.DataFrame({\n",
    "            \"Values\": [temp.count()],\n",
    "            \"Unique\": [temp.nunique()],\n",
    "            \"Start\": [temp.min()],\n",
    "            \"End\": [temp.max()],\n",
    "            \"Missing\": [temp.isnull().sum()],\n",
    "            })\n",
    "        desc_stats[\"Missing_Percentage\"]= (desc_stats[\"Missing\"]/(desc_stats[\"Values\"]+ desc_stats[\"Missing\"]))* 100\n",
    "        desc_stats[\"Distinct\"]= temp.nunique()\n",
    "        desc_stats[\"Distinct_Percentage\"]= (desc_stats[\"Distinct\"]/(desc_stats[\"Values\"]+ desc_stats[\"Missing\"]))* 100\n",
    "        desc_stats[\"Values_Percentage\"]= 100- desc_stats[\"Missing_Percentage\"]\n",
    "        \n",
    "        if False:\n",
    "            std_df= pd.DataFrame({\"Time_1\":self.df[colname].sort_values()[1:].to_list(), \"Time_2\": self.df[colname].sort_values()[:-1].to_list()})\n",
    "            std_df[\"Time_diff\"]= (std_df[\"Time_1\"]- std_df[\"Time_2\"])\n",
    "            std_df[\"Time_diff_in_sec\"]= (std_df[\"Time_1\"]- std_df[\"Time_2\"]).dt.total_seconds()\n",
    "            desc_stats[\"Std\"]= str(std_df[\"Time_diff_in_sec\"].std().round(floating_point_limit))+ \" sec\"\n",
    "        else:\n",
    "            desc_stats[\"Std\"]= None\n",
    "\n",
    "        return desc_stats \n",
    "\n",
    "    def cat_feacture_desc_stats(self, colname):\n",
    "        temp=  self.df[colname]\n",
    "        desc_stats= pd.DataFrame({\n",
    "            \"Values\": [temp.count()],\n",
    "            \"Unique\": [temp.nunique()],\n",
    "            \"Missing\": [temp.isnull().sum()],\n",
    "            })\n",
    "        desc_stats[\"Missing_Percentage\"]= (desc_stats[\"Missing\"]/(desc_stats[\"Values\"]+ desc_stats[\"Missing\"]))* 100\n",
    "        desc_stats[\"Distinct\"]= temp.nunique()\n",
    "        desc_stats[\"Distinct_Percentage\"]= (desc_stats[\"Distinct\"]/(desc_stats[\"Values\"]+ desc_stats[\"Missing\"]))* 100\n",
    "        desc_stats[\"Values_Percentage\"]= 100- desc_stats[\"Missing_Percentage\"]\n",
    "        # print(temp.std())\n",
    "\n",
    "        return desc_stats   #.round(decimals=2)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEDA():\n",
    "    def __init__(self, df_path, htmlfilename= \"AutoEDA.html\", **karwas):\n",
    "        '''Any keyarugemts needed to read the datafile send it inside 'datafile' keyargument'''\n",
    "        self.df= pd.DataFrame()\n",
    "        self.__read_from_file(df_path)\n",
    "        \n",
    "        self.__constrains_for_df_extract__(htmlfilename)\n",
    "        self.no_of_steps= 4\n",
    "        self.create_html()\n",
    "        \n",
    "\n",
    "    def __read_from_file(self, df_path):\n",
    "        if type(df_path)== pd.core.frame.DataFrame:\n",
    "            self.df= df_path\n",
    "        elif not os.path.exists(df_path):\n",
    "            raise ValueError('Not a valid path or pandas dataframe')\n",
    "        else:\n",
    "            try:\n",
    "                df_path= os.path.normpath(df_path)\n",
    "                if df_path.lower().endswith('.csv'):\n",
    "                    self.df= pd.read_csv(df_path)\n",
    "                elif df_path.lower().endswith('.xml'):\n",
    "                    self.df= pd.read_xml(df_path)\n",
    "                elif df_path.lower().endswith('.table'):\n",
    "                    self.df= pd.read_table(df_path)\n",
    "                elif df_path.lower().endswith('.json'):\n",
    "                    self.df= pd.read_json(df_path)\n",
    "                elif df_path.lower().endswith(tuple(['xls' , 'xlsx' , 'xlsm' , 'xlsb' , 'odf' , 'ods', 'odt'])):\n",
    "                    self.df= pd.read_excel(df_path)\n",
    "                elif df_path.lower().endswith('.html'):\n",
    "                    self.df= pd.read_html(df_path)\n",
    "                else:\n",
    "                    raise ValueError('Not a valid file format, Supported file types are: csv, xml, table, json, html, excel')\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "\n",
    "    def __constrains_for_df_extract__(self, htmlfilename):\n",
    "        self.html_out_file= htmlfilename\n",
    "        self.datatypes_for_corr_plot= [np.number, 'datetime64', 'category', 'bool']\n",
    "        self.img_type= 'png'\n",
    "        self.pairplot_sample_size= 50\n",
    "        self.floating_point_limit= 3\n",
    "\n",
    "    def write_html_header(self, df_overiew_html, df_details_html):\n",
    "        '''This function wirtes dataframe overview and css file in the html file'''\n",
    "        html_content_start= '<!DOCTYPE html><html><head><link rel=\"stylesheet\" href=\"AutoEDA.css\"><title>AutoEDA</title></head><body>'\n",
    "        html_file = open(self.html_out_file, \"w\")\n",
    "        html_file.write(html_content_start+ df_overiew_html+ df_details_html)\n",
    "        html_file.close()\n",
    "        \n",
    "    def write_html_tail(self):\n",
    "        '''This function wirtes the end of the html file and javascripts file in the html file'''\n",
    "        html_content_end= '''<script>\n",
    "        function displayrightdiv(id, divclass) {\n",
    "            var element = document.getElementById(id);\n",
    "            if (element.style.display !== 'block') {\n",
    "                var elements = document.getElementsByClassName(divclass);\n",
    "                for (var i = 0; i < elements.length; i++) {\n",
    "                  elements[i].style.display = 'none';\n",
    "                }\n",
    "                element.style.display = 'block';\n",
    "            element.style.display = 'block';\n",
    "            } else {\n",
    "                element.style.display = 'none';\n",
    "            }\n",
    "        }\n",
    "        </script></body></html>'''\n",
    "        html_file = open(self.html_out_file, \"a\")\n",
    "        html_file.write(html_content_end)\n",
    "        html_file.close()\n",
    "\n",
    "    def create_html(self):\n",
    "        #HTML df overiew:\n",
    "        print(f\"step 1/{self.no_of_steps}: initializing dataframe\")\n",
    "        auto_eda_helper= AutoEDAHelper(self.df)\n",
    "        df_overiew_html, df_details_html= auto_eda_helper.df_overview_as_html(self.datatypes_for_corr_plot, self.pairplot_sample_size, self.floating_point_limit, self.img_type)\n",
    "        self.write_html_header(df_overiew_html, df_details_html)\n",
    "\n",
    "        return\n",
    "        #HTML write all feature details:\n",
    "        print(f\"step 2/{self.no_of_steps}: extracting information for each columns\")\n",
    "        col_and_type_mapping= auto_eda_helper.get_features_type\n",
    "        for colname in (pbar:= tqdm(col_and_type_mapping)):\n",
    "            pbar.set_postfix_str(colname)\n",
    "            df_overiew_html, df_details_html= auto_eda_helper.feacture_as_html(colname)\n",
    "            html_file = open(self.html_out_file, \"a\")\n",
    "            html_file.write(\"\\n\"+df_overiew_html+\"\\n\")\n",
    "            html_file.write(\"\\n\"+df_details_html+\"\\n\")\n",
    "            html_file.close()\n",
    "\n",
    "        #HTML write tail: -js, etc\n",
    "        print(f\"step 3/{self.no_of_steps}: wrapping up html\")\n",
    "        self.write_html_tail()\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1/4: initializing dataframe\n"
     ]
    }
   ],
   "source": [
    "# dataset_file= R\"D:\\Scaler\\projects\\automated_eda\\dataset_in\\Online Retail II UCI\\online_retail_II.csv\"\n",
    "# dataset_file= R\"D:\\Scaler\\projects\\automated_eda\\dataset_in\\Credit EDA Case Study\\application_data.csv\"\n",
    "dataset_file= R\"D:\\Scaler\\projects\\automated_eda\\dataset_in\\basketball_players.csv\"\n",
    "\n",
    "auto_eda= AutoEDA(dataset_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
